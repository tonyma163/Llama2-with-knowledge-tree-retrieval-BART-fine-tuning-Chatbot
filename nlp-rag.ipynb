{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7928487,"sourceType":"datasetVersion","datasetId":4659852},{"sourceId":8144823,"sourceType":"datasetVersion","datasetId":4816177}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain accelerate peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T15:52:25.840834Z","iopub.execute_input":"2024-04-17T15:52:25.841499Z","iopub.status.idle":"2024-04-17T15:52:38.742905Z","shell.execute_reply.started":"2024-04-17T15:52:25.841455Z","shell.execute_reply":"2024-04-17T15:52:38.741631Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.16)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.32 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.33)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.43)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.48)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Load Fine-tuned Model**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BartForConditionalGeneration\nfrom peft import PeftModel\nimport torch\n\nbase_model = \"fnlp/bart-base-chinese\"\nnew_model = \"tonyma163/bart_v1\"\n\ndevice=\"cuda:0\"\n\nbase_model_reload = BartForConditionalGeneration.from_pretrained(\n        base_model,\n        return_dict=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        device_map=device,\n        #trust_remote_code=True,\n)\nbase_model_reload.half()\n\nmodel = PeftModel.from_pretrained(base_model_reload, new_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:46.341471Z","iopub.execute_input":"2024-04-17T15:52:46.341833Z","iopub.status.idle":"2024-04-17T15:52:55.442217Z","shell.execute_reply.started":"2024-04-17T15:52:46.341803Z","shell.execute_reply":"2024-04-17T15:52:55.441127Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-17 15:52:49.817720: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-17 15:52:49.817777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-17 15:52:49.819394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(base_model, trust_remote_code=True)\n\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:55.444198Z","iopub.execute_input":"2024-04-17T15:52:55.445495Z","iopub.status.idle":"2024-04-17T15:52:55.615291Z","shell.execute_reply.started":"2024-04-17T15:52:55.445450Z","shell.execute_reply":"2024-04-17T15:52:55.614498Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import Text2TextGenerationPipeline\n\npipe = Text2TextGenerationPipeline(model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:52:59.640147Z","iopub.execute_input":"2024-04-17T15:52:59.641033Z","iopub.status.idle":"2024-04-17T15:52:59.646516Z","shell.execute_reply.started":"2024-04-17T15:52:59.640999Z","shell.execute_reply":"2024-04-17T15:52:59.645610Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"The model 'PeftModelForSeq2SeqLM' is not supported for . Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pipe('周迅的星座是什么？')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading Document**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport ast\n\nfile_path = \"/kaggle/input/nlp-knowledge-set/knowledge_set.txt\"\n\ndata = []\n\n# Open the file and parse each line from string to tuple\nwith open(file_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        if line.strip():  # Ensure the line is not empty\n            try:\n                # Convert string representation of tuple to actual tuple\n                tuple_data = ast.literal_eval(line.strip())\n                data.append(tuple_data)\n            except SyntaxError:\n                print(f\"Skipping malformed line: {line.strip()}\")\n\n# Load the data into a DataFrame\ndf = pd.DataFrame(data, columns=['Entity', 'Category', 'Answer'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:11.293328Z","iopub.execute_input":"2024-04-17T15:53:11.294198Z","iopub.status.idle":"2024-04-17T15:53:11.786921Z","shell.execute_reply.started":"2024-04-17T15:53:11.294163Z","shell.execute_reply":"2024-04-17T15:53:11.786077Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Knowledge Graph**","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport pandas as pd\n\n# Create a directed graph\nG = nx.DiGraph()\n\n# Add nodes and edges based on the DataFrame\nfor index, row in df.iterrows():\n    entity_node = f\"Entity: {row['Entity']}\"\n    category_node = f\"{entity_node}, Category: {row['Category']}\"\n    answer_node = f\"Answer: {row['Answer']}\"\n\n    # Add nodes and edges\n    G.add_node(entity_node, type='Entity')\n    G.add_node(category_node, type='Category', entity=row['Entity'])\n    G.add_node(answer_node, type='Answer', category=row['Category'])\n    \n    G.add_edge(entity_node, category_node)\n    G.add_edge(category_node, answer_node)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:13.440187Z","iopub.execute_input":"2024-04-17T15:53:13.441052Z","iopub.status.idle":"2024-04-17T15:53:16.132585Z","shell.execute_reply.started":"2024-04-17T15:53:13.441014Z","shell.execute_reply":"2024-04-17T15:53:16.131754Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Example query: Find all answers linked to a specific entity and category\nentity_query = '西宁'\ncategory_query = '2018-11-14'\n\nprocessed_entity_query = f\"Entity: {entity_query}\"\nprocessed_category_query = f\"{processed_entity_query}, Category: {category_query}\"\n\n# First, find the category node directly connected to the entity\nif (processed_entity_query, processed_category_query) in G.edges:\n    answers = [node for node in G.successors(processed_category_query) if G.nodes[node]['type'] == 'Answer']\n    for answer in answers:\n        print(answer)\nelse:\n    print(\"No such category for the given entity or wrong category/entity combination.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:16.134158Z","iopub.execute_input":"2024-04-17T15:53:16.134455Z","iopub.status.idle":"2024-04-17T15:53:16.141353Z","shell.execute_reply.started":"2024-04-17T15:53:16.134430Z","shell.execute_reply":"2024-04-17T15:53:16.140488Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Answer: 阴,东风,最高气温:5℃,最低气温:-4℃\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Find the Entity Only**","metadata":{}},{"cell_type":"code","source":"# Entity Only\ndef query_by_entity(graph, entity):\n    # Create a comprehensive list to store results\n    results = []\n\n    # Construct the entity node identifier\n    entity_node = f\"Entity: {entity}\"\n\n    # Check if the entity node exists in the graph\n    if entity_node in graph:\n        # Get all category nodes linked to the entity\n        category_nodes = [node for node in G.successors(entity_node) if G.nodes[node]['type'] == 'Category']\n        \n        for category in category_nodes:\n            # Retrieve all answer nodes linked to this category\n            answer_nodes = [node for node in G.successors(category) if G.nodes[node]['type'] == 'Answer']\n            results.append((category, answer_nodes))\n    else:\n        print(f\"No information available for entity: {entity}\")\n    \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:26.558145Z","iopub.execute_input":"2024-04-17T15:53:26.558832Z","iopub.status.idle":"2024-04-17T15:53:26.565713Z","shell.execute_reply.started":"2024-04-17T15:53:26.558798Z","shell.execute_reply":"2024-04-17T15:53:26.564727Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Query the graph for a specific entity\nentity = \"周迅\"\nresults = query_by_entity(G, entity)\n\n# Print the results\nif results:\n    print(f\"Information for entity '{entity}':\")\n    for category, answers in results:\n        print(f\"\\n{category}:\")\n        for answer in answers:\n            print(f\"  - {answer}\")\nelse:\n    print(\"No results found for the queried entity.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:28.952652Z","iopub.execute_input":"2024-04-17T15:53:28.953011Z","iopub.status.idle":"2024-04-17T15:53:28.961495Z","shell.execute_reply.started":"2024-04-17T15:53:28.952983Z","shell.execute_reply":"2024-04-17T15:53:28.960286Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Information for entity '周迅':\n\nEntity: 周迅, Category: 评论:\n  - Answer: 灵气逼人，倔犟，聪慧\n  - Answer: 我的妈呦这土boqi嗓子\n  - Answer: 每一个形象都演活了。\n  - Answer: 竟然和我喜欢的刘若英是好友，果然都是小资\n  - Answer: 在天朝唯一喜欢的演员\n  - Answer: 喜欢她的身体散发出的各种灵气，甚至是她的嗓音·\n  - Answer: 中国大陆目前演技最好的演员。\n  - Answer: 到现在都还有灵气，真的很难得\n  - Answer: amazinglady\n  - Answer: 演技、容貌、修养，三方面俱佳，缺点太少。\n  - Answer: 看完听风者终于坚定了支持周迅的决心~~\n  - Answer: 演技和纯真的完美结合，不做作，不矫情\n  - Answer: 小精灵，很享受她的美\n  - Answer: 太喜欢了一直很喜欢。\n  - Answer: #印象周迅#孙纳和张学宁\n  - Answer: 美人~~~对演艺事业有强烈追求的演员~~\n  - Answer: 挺喜欢她的~觉得演什么都像\n  - Answer: 借用一句台词，“怎么会有如此好德又好色的人呢？”\n  - Answer: 目前内地唯一有精湛演技的女生！\n  - Answer: 这样的女人真的很别致\n  - Answer: 公子！我宣你！我也宣萱！\n  - Answer: #印象周迅#周公子生日快乐\n  - Answer: 内地最好的女演员，没有之一。我说的是演技\n  - Answer: 早期其实并不喜欢你……看了《李米的猜想》才喜欢上了你\n  - Answer: 就是喜欢你。演技超好，脸蛋真漂漂。\n  - Answer: 为什么打九分看看，《李米的猜想》\n  - Answer: 大爱周迅！美丽、灵！\n  - Answer: 有灵气的演员，喜欢她的笑\n  - Answer: 最喜欢有独特气质的人了\n  - Answer: 周迅，中国真正好的女演员\n  - Answer: 我从来不知道什么叫淑女，更不装，我活的随意！\n  - Answer: 她身上有股子灵气，学是学不来的~~~\n  - Answer: 从大明宫词开始就很喜欢你那聪明空灵的劲。。。\n  - Answer: 魅力与灵气集于一身的气质派、实力派演员。\n  - Answer: 把灵魂赋予角色的精灵\n  - Answer: 不是神，不是仙，却有一种灵气········\n  - Answer: #印象周迅#喜欢风声和画皮里的周迅~~\n  - Answer: 演戏很好，长得一般，人品太差\n  - Answer: 她的眼睛里写满纯真与执着。。\n  - Answer: 拿个三大电影节之一的影后吧\n  - Answer: 中国难得的天才年轻女演员，绝对的实力派！\n  - Answer: 很有想法很有远见的女人\n  - Answer: #印象周迅#风声和听风者\n  - Answer: 怎么说呢，我被她迷倒了。\n  - Answer: 瘦小的周迅的确很会演戏\n  - Answer: 她的电影比电视好看，而且，现在可能无人出得起价钱请她做电视了\n  - Answer: 迄今为止演艺圈最有灵性的内地女演员\n  - Answer: 小小的身体蕴含无限大的力量\n  - Answer: 希望你早日找到你的真爱，开心幸福生活下去。\n  - Answer: 很古典，很民国的小女子\n  - Answer: #印象周迅#看的不多。最喜欢《鸳鸯蝴蝶》中的角色~~~\n  - Answer: 我居然一直没给评分！！！\n  - Answer: 古灵精怪，天才的表演家！\n  - Answer: 中国绝对不可多得的好演员···\n  - Answer: 还未落地的精灵，华语影坛的幸运星。\n  - Answer: #印象周迅#好演员，支持！！！！\n  - Answer: 很喜欢你，喜欢你的声音。喜欢你的小巧却不失张力\n  - Answer: #印象周迅#那时花开啊，文艺范\n  - Answer: 迅哥儿，生日快乐。一切安好。\n  - Answer: #印象周迅#好萌好萌好萌，好像扑上去抱在怀里！！！\n  - Answer: 最爱大明宫词的小太平\n  - Answer: 我觉得周迅是当今华语影坛女演员第一人\n  - Answer: 是滥性而不是随性的女人\n  - Answer: 精明很懂得经营自己\n  - Answer: 越来越喜欢她了，很忧郁性感而且妩媚\n  - Answer: 每一次的变化，都给我带来不一样的震撼！\n  - Answer: 她前三辈子一定都是演戏的！天生的戏精啊~！蛮喜欢的~\n  - Answer: 不管是老鬼，还是小唯，她永远那么美！\n  - Answer: 清新，自然，有灵气！\n  - Answer: 她是真正的为演艺而生。前无借鉴，后无来者。\n  - Answer: 演技真心好！另外时光的获奖记录漏了好多……\n  - Answer: 灵气逼人，日臻成熟，天生的演员\n  - Answer: 二流演技，三流脸蛋，嗓音，还是饶了我吧。\n  - Answer: 周迅将是中国娱乐界的下一个或下下一个笑话！！你们等着吧！！\n  - Answer: 我一直最欣赏她的两点:坦率以及演戏的认真。\n  - Answer: #印象周迅#她在《风声》中的表演真的很震撼\n  - Answer: #印象周迅#我爱她，爱她低沉磁性的嗓音，爱她一颦一笑。\n  - Answer: 从小就喜欢她~~~~~~~~~~\n  - Answer: #印象周迅#还是第一次看的印象比较深刻，是《橘子红了》\n  - Answer: 粵語給跪，咋練的教教我\n  - Answer: 中国最伟大的青年女演员，没有之一\n  - Answer: 喜欢《风声》里德顾晓梦\n  - Answer: 中国内地最有灵气的最真的女演员。\n  - Answer: 周公子的短发，很喜欢\n  - Answer: 中国影人中最爱的精灵天使~\n  - Answer: 中国最好的女演员，没有之一。\n  - Answer: 他的戏总让我感觉到骄傲\n  - Answer: 中国一线女星中演技最好的一个！\n  - Answer: 两只大眼睛里都是沧桑\n  - Answer: 真心喜欢迅哥~从小娇妻开始到太平公主到李米再到小唯\n  - Answer: 比喜欢赵薇还喜欢周迅。\n  - Answer: #印象周迅#祝迅哥生日快乐\n  - Answer: #印象周迅#洒脱干练，也可风情万种~生日快乐哇~[鼓掌]\n  - Answer: 她是一个靠自己的演技吃饭的演员\n  - Answer: 很好!!!!!!!!!\n  - Answer: 平时有点口吃，不善言谈。一演起戏来就像打了鸡血一样的惊艳。\n  - Answer: 古灵精怪的女生，演技好到没话说，赞一个！\n  - Answer: 仅就演技而言，真的不错。不过很可惜，不是我喜欢的类型。。\n  - Answer: #印象周迅#李米的猜想\n  - Answer: 两部画皮彻底惊艳~~\n  - Answer: 如果问我我喜欢哪个女星的话，那第一时间想到的是她，周迅。\n  - Answer: 少年太平爱上薛昭的那一刻，我爱上周公子\n  - Answer: 看了你的李米才突然发现戏演的真好。\n  - Answer: 内敛、低调，会演戏的女演员。\n  - Answer: 灵气闪耀，大陆最难得的女演员之一。\n  - Answer: 灵性，人物拿捏得十分到位\n  - Answer: 江南女孩那种外柔内刚的气质在她身上体现的可是淋漓尽致！\n  - Answer: 英气，执着，冷静的深情\n  - Answer: 内地女星中的chanel\n  - Answer: 演技与灵气，足以笑傲江湖\n  - Answer: 灵气十足，大银幕上给人的范儿是很多女星所不能比的！\n  - Answer: 如果不是公鸭嗓该多好\n  - Answer: 难看，不是我的审美观\n  - Answer: #印象周迅#李米如果爱\n  - Answer: 大陆最优秀的女演员。没有之一。\n  - Answer: 其实这小妮子身上那股子倔强的劲儿我特喜欢。\n  - Answer: 演戏非常狠，真性情~\n  - Answer: #印象周迅#很有风味的女人！\n\nEntity: 周迅, Category: 获奖:\n  - Answer: 华语电影传媒大奖_最佳女演员\n  - Answer: 台湾电影金马奖_金马奖-最佳原创歌曲\n  - Answer: 香港电影金像奖_金像奖-最佳原创电影歌曲奖\n  - Answer: 大众电影百花奖_最佳女主角\n  - Answer: 香港电影金像奖_金像奖-最佳女主角\n  - Answer: 亚洲电影大奖_最佳女演员\n  - Answer: 香港电影金像奖_金像奖-最佳女配角\n  - Answer: 中国电影金鸡奖_最佳女配角\n  - Answer: 台湾电影金马奖_金马奖-最佳女主角奖\n  - Answer: 中国电影金鸡奖_最佳女主角\n\nEntity: 周迅, Category: 成就:\n  - Answer: 亚洲电影大奖最佳女主角\n  - Answer: 中国电视金鹰奖最受欢迎女演员\n  - Answer: 香港电影金像奖最佳女主角\n  - Answer: 香港电影金紫荆奖最佳女主角\n  - Answer: 大众电影百花奖最佳女主角\n  - Answer: 上海电视节白玉兰奖最佳女演员\n  - Answer: 台湾电影金马奖最佳女主角\n  - Answer: 中国电影金鸡奖最佳女主角\n  - Answer: 中国电影导演协会最佳女演员\n\nEntity: 周迅, Category: 身高:\n  - Answer: 161cm\n\nEntity: 周迅, Category: 新闻:\n  - Answer: 近日，有媒体曝据某知名亲近周迅的一线女星爆料，周迅确定已与高圣远离婚举证高圣远反常反应称两人一直仿佛分居，生活早没交集，刚好又没孩子包袱，了断起来也一干二净周迅方回应没离。请多关注公益。周迅否认与高圣远离婚:请大家多关注公益\n  - Answer: 4日，中国明星周迅汤唯刘雯胡歌刘诗诗桂纶镁牛莉田海蓉等现身巴黎时装周。周迅清新妆容短裙秀美腿；辣妈汤唯橙色礼服仙气飘飘；刘诗诗短发超英俊...谁的造型让你动心？中国明星巴黎看秀女神齐聚比美胡歌尽显绅士范\n  - Answer: 继《如果爱》之后，每隔一段时间周迅都会“消失”一下，但近年的她似乎愈发“离群”。周迅说，在不拍戏也没通告的日子，除了发呆似乎就不知道该做些什么了，甚至连兴趣爱好都要开始寻找。这样的日子虽然并非时时快乐，但她更享受随心所欲的心境。\n  - Answer: 全国政协委员、致公党中央常务副主席蒋作君说，“现在少年儿童知道周迅的人多，知道鲁迅的人少；知道比尔的多，知道保尔的少”。并建议着力培育少年儿童的创新、动手能力，着力教育少年儿童牢固树立社会主义核心价值观。全国政协委员蒋作君:现在少年儿童知道周迅的人多，知道鲁迅的人少\n  - Answer: 近日，一组胡歌周迅合体拍摄的写真大片曝光照片中胡歌帅气灿笑，周迅灵动似少女，真是男帅女靓配一脸下棋的那张美到我了→,\n  - Answer: 周迅说，该书还无中生有，捏造虚假信息。捏造“周迅和王烁分手的原因流传着很多不同版本，原因中竟有“怀孕并流产版”这种严重不负责任的虚假消息，使得讹传经各种途径广泛传播，给周迅造成了持续的伤害，严重损害了她的名誉权。\n  - Answer: 【周迅起诉《苦女人周迅》一书侵权索赔95万】周迅说，该书还无中生有，捏造虚假信息。捏造“周迅和王烁分手的原因流传着很多不同版本，原因中竟有“怀孕并流产版”这种严重不负责任的虚假消息，使得讹传经各种途径广泛传播，给周迅造成了持续的伤害，严重损害了她的名誉权。\n\nEntity: 周迅, Category: 主演:\n  - Answer: 嘿玛嘿玛\n  - Answer: 桂林荣记\n  - Answer: 苏州河\n  - Answer: 生死劫\n  - Answer: 小王子\n  - Answer: 巴尔扎克和小裁缝\n  - Answer: 香港有个好莱坞\n  - Answer: 遥远星球的孩子\n  - Answer: 风声\n  - Answer: 龙门飞甲\n  - Answer: 如果·爱\n  - Answer: 李米的猜想\n  - Answer: 鸳鸯蝴蝶\n\nEntity: 周迅, Category: 血型:\n  - Answer: O型\n\nEntity: 周迅, Category: 星座:\n  - Answer: 天秤座\n\nEntity: 周迅, Category: 生日:\n  - Answer: 1974-10-18\n\nEntity: 周迅, Category: 演唱:\n  - Answer: 给小孩\n  - Answer: 承诺(内地版)\n\nEntity: 周迅, Category: 出生地:\n  - Answer: 中国浙江衢州\n\nEntity: 周迅, Category: 体重:\n  - Answer: 41kg\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Document Splitting, Embedding, and Vector Store**","metadata":{}},{"cell_type":"markdown","source":"**Query Engine**","metadata":{}},{"cell_type":"markdown","source":"**Query the LLM**","metadata":{}},{"cell_type":"code","source":"def retrieve_from_graph(graph, query_entity):\n    # This function will be similar to the earlier function but tailored for RAG integration\n    entity_node = f\"Entity: {query_entity}\"\n    relevant_data = []\n\n    if entity_node in graph:\n        category_nodes = [node for node in G.successors(entity_node) if G.nodes[node]['type'] == 'Category']\n        for category in category_nodes:\n            answers = [node for node in G.successors(category) if G.nodes[node]['type'] == 'Answer']\n            relevant_data.extend(answers)\n    return relevant_data","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:38.876225Z","iopub.execute_input":"2024-04-17T15:53:38.876945Z","iopub.status.idle":"2024-04-17T15:53:38.883094Z","shell.execute_reply.started":"2024-04-17T15:53:38.876912Z","shell.execute_reply":"2024-04-17T15:53:38.882038Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def generate_response(input_query, graph):\n    # Retrieve relevant information from the graph\n    retrieved_data = retrieve_from_graph(graph, input_query)\n    context = \" \".join(retrieved_data)\n    print(f\"context: {context}\\n\")\n    # Combine the input query with the retrieved context\n    combined_input = f\"Query: {input_query} Context: {context}\"\n    \n    #return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    inputs = tokenizer.encode(combined_input, return_tensors=\"pt\")\n    outputs = model.generate(input_ids=inputs.to(device), max_new_tokens=126)\n    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return {\"response\": response_text}","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:53:49.253187Z","iopub.execute_input":"2024-04-17T15:53:49.253763Z","iopub.status.idle":"2024-04-17T15:53:49.260678Z","shell.execute_reply.started":"2024-04-17T15:53:49.253721Z","shell.execute_reply":"2024-04-17T15:53:49.259656Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_query = \"郭富城\"\nresponse = generate_response(input_query, G)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:56:52.778043Z","iopub.execute_input":"2024-04-17T15:56:52.778441Z","iopub.status.idle":"2024-04-17T15:56:55.481920Z","shell.execute_reply.started":"2024-04-17T15:56:52.778408Z","shell.execute_reply":"2024-04-17T15:56:55.480517Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"context: Answer: 人气天王 Answer: 娱圈高调炫富土豪明星 Answer: 名人 Answer: 那些爱穿裙子的男星 Answer: 男神级明星 Answer: 香港重量级明星 Answer: 广告商的宠儿 Answer: 那些腿短的男神们 Answer: 歌神 Answer: 大眼明星 Answer: 金马奖影帝 Answer: 明星成名前的打工经历 Answer: 爱车之人 Answer: 娱乐圈的钻石王老五 Answer: 天蝎座男明星 Answer: 香港歌坛天王 Answer: “天王” Answer: 心细 Answer: 浪漫 Answer: 香港男星 Answer: 性感 Answer: 中国知名影星 Answer: 古装剧中帅气男演员 Answer: 香港歌手 Answer: 超级巨星 Answer: “侦探” Answer: 亚洲天王 Answer: 大器晚成的影帝 Answer: 娱乐圈内的钻石王老五 Answer: 那些被结婚的明星们 Answer: 明星的初恋情人 Answer: 香港影帝 Answer: 国际巨星 Answer: 舞神 Answer: 老牌明星 Answer: 演艺圈的劳模 Answer: 观众眼中的梦中情人 Answer: 很低调的人 Answer: 联合国儿童基金会大使 Answer: 大男孩 Answer: 娱乐圈有钱任性土豪明星 Answer: 天王巨星 Answer: 很有才华的艺人 Answer: 演员 Answer: 细心 Answer: 酷劲十足 Answer: 那些颜值超高的赛车男神 Answer: 创造吉尼斯纪录的明星们 Answer: 港星 Answer: “舞台王者” Answer: 一众艺人 Answer: 那些高调分手的娱乐圈明星 Answer: 影帝 Answer: 国际影星 Answer: 网友心中的土豪明星 Answer: 娱乐圈的肌肉型男 Answer: 先锋人物 Answer: 肌肉型男 Answer: 舞台型歌手 Answer: “表演艺术家” Answer: 香港人气歌手 Answer: 影星 Answer: 大好人 Answer: 那些恐婚症男星 Answer: 运动品牌的明星代言人 Answer: 娱乐圈的恐婚男星 Answer: 纯真 Answer: \"造型王\" Answer: 娇小 Answer: 创吉尼斯纪录明星们 Answer: 性感的男人 Answer: 不老男神 Answer: 电台名嘴 Answer: 歌坛天王 Answer: 香港天王 Answer: 健谈 Answer: 全能的艺人 Answer: 为影片剃光头的明星 Answer: 金马金像双料影帝 Answer: 港台天王 Answer: 乐坛天王 Answer: 香港乐坛史实力巨星 Answer: 亚洲影帝 Answer: 人气最旺 Answer: 有情有意却不结婚的明星 Answer: 分手后还能做朋友的明星 Answer: 让人心肝乱颤的古装美男们 Answer: 完美主义者 Answer: 娱乐圈初恋时就被甩的明星 Answer: 真正的演技派 Answer: 天王偶像 Answer: 香港人 Answer: 型男 Answer: 魅力男神 Answer: 中国明星 Answer: 万人迷 Answer: 老牌天王 Answer: 性格外向 Answer: 娱乐圈钻石王老五 Answer: 金像奖影帝 Answer: 潇洒 Answer: 娱乐圈的极品剩男剩女 Answer: 华语不老男歌手 Answer: 洒脱 Answer: 歌坛巨星 Answer: “常青树” Answer: “影帝” Answer: 天王影帝 Answer: 很大方的人 Answer: 国宝级钻石王老五 Answer: 一向感情低调 Answer: 肌肉男 Answer: “不老男神” Answer: 帅帅 Answer: 俊朗 Answer: 频频被结婚的众明星 Answer: 最帅的男人 Answer: 成熟 Answer: 男神 Answer: 好男人 Answer: 高调炫富的明星 Answer: “实力派” Answer: 娱乐圈要爱情不要婚姻明星 Answer: 花心的人 Answer: 天王 Answer: 家喻户晓人物 Answer: 跟经纪人谈恋爱的明星 Answer: 伟大 Answer: 香港歌星 Answer: “老艺术家” Answer: 娱乐圈被商标明星 Answer: “劳模” Answer: 偶像 Answer: 永恒的经典 Answer: 著名的影星 Answer: 低调 Answer: 世纪偶像 Answer: 向来低调 Answer: “亚洲舞王” Answer: 明星 Answer: 偶像派 Answer: 帅气 Answer: 香港艺人 Answer: 国际知名影星 Answer: 外形出众 Answer: 天王级明星 Answer: 三不男人 Answer: 娱乐圈的短腿男神 Answer: 不错的艺人 Answer: 好歌手 Answer: “男神” Answer: 亚洲天王巨星 Answer: 幽默的人 Answer: “一哥” Answer: 香港影星 Answer: 职业偶像 Answer: 香港明星 Answer: 娱乐圈天王 Answer: 小编的偶像 Answer: “小李子” Answer: 花花公子 Answer: “舞王” Answer: 创造吉尼斯纪录的明星 Answer: 那些总是被结婚的明星 Answer: 文娱明星 Answer: 被结婚的明星们 Answer: 中国香港男星 Answer: 金马奖双料影帝 Answer: 恋爱超五年遗憾分手的明星 Answer: “金马影帝” Answer: 四小天王 Answer: 老男人 Answer: 香港电影金像奖_金像奖-最佳原创电影歌曲奖 Answer: 台湾电影金马奖_金马奖-最佳男主角奖 Answer: 香港电影金像奖_金像奖-最佳男主角 Answer: 中国电影金鸡奖_最佳男主角 Answer: 香港电影金像奖_金像奖-最佳男配角 Answer: 你是我很值得学习的人--榜样！！！ Answer: 老郭找了个绿婊，这几天被媒体和网友狂轰乱炸的 Answer: 说城演技不好的请去看父子、杀人犯、白银帝国。。。 Answer: 小时候跟哥哥喜欢上的他 Answer: 貌似都是老了老了演技就出来了。。。 Answer: 你们都干什么啊外国演员全部高分崇洋媚外啊 Answer: 看得出如今的郭天王真的很努力，但是总是欠缺点运气。 Answer: 挺喜欢他在三岔口中的表演～我喜欢那样子的男的｀真的很ＭＡＮ～ Answer: 多多拍戏~~~用心啊，阿城！！！ Answer: 大哥哥，您的歌对我帮助很大。 Answer: 因为在原本不怎么样的故事《罪与罚》中的表演震撼到我了。 Answer: 香港演员中最真诚的一位。 Answer: 我们永远的舞王！！！ Answer: 努力用心演戏很值得学习 Answer: 从上初中就很喜欢不管唱歌，跳舞还是演戏！很帅！ Answer: 喜欢两部《寒战》和《冲锋陷阵》 Answer: 永远的偶像！永远的天王！永远的舞王！永远的影帝！ Answer: 玩嫩模，露下体。露下体，玩嫩模。 Answer: 郭富城的表演越来越好了！ Answer: 魅力四射!!!永远的偶像 Answer: 看了《罪与罚》真的很惊讶啊 Answer: 实力派明星，歌影双雄！ Answer: 一直在努力超越自己的完美男人，期待你的音乐剧！ Answer: 最喜欢《侦探》三部曲中的神经质表演 Answer: 他在最爱中的表演可以说是脱胎换骨！ Answer: 20世纪中国最帅的男人 Answer: 喜欢在寒战和全民目击的表现，史上最帅的牛魔王！ Answer: 城城被黑了么，这么低的分。 Answer: 说实话，时光网上的分给的太低了 Answer: 年龄大了，反而变得更加的迷人... Answer: 明年不出意外的话，，金像影帝应该是城城了 Answer: 一点没觉得矮是他的缺点，越老越有味道，比刘德华性感多了。 Answer: 我靠，有必要黑那么低分吗？？？？ Answer: 电影拍的越来越好了！希望你音乐剧也不要放弃！ Answer: 越来越有魅力，从活力四射到深沉忧郁 Answer: 老郭家的人，支持支持。 Answer: oneofthebest Answer: 其实他可以做一个好演员，不应该去唱歌。 Answer: 他的努力，工作的态度。就是新人的榜样！ Answer: 绝对靠演技的帅气演员。 Answer: 喜欢了十五年的老郭啊 Answer: 从小学开始就喜欢到现在，没办法，他就是一直吸引我 Answer: 次奥，怎么这么低？黑子能不能给个解释？ Answer: 更喜欢做回演员的郭富城。 Answer: 终于见识影帝的演技了。 Answer: 动感的舞步，英俊的外表！！！ Answer: 超爱踏血寻梅中的表演！ Answer: 全民目击 Answer: 寒战 Answer: 柔道龙虎榜 Answer: 最爱 Answer: 踏血寻梅 Answer: 1:99电影行动 Answer: 安娜玛德莲娜 Answer: 罪与罚 Answer: 小亲亲 Answer: 父子 Answer: 赤脚小子 Answer: 浮城大亨 Answer: 你是我的英雄 Answer: 一届香港电影金像奖最佳男主角奖 Answer: 三届十大劲歌金曲最受欢迎男歌星 Answer: 联合国儿童基金会香港委员会大使 Answer: 百事音乐名人堂大奖 Answer: 内华达州国际杰出艺人奖 Answer: 长春国际电影节最佳男主角 Answer: 香港舞蹈年奖 Answer: 吉尼斯世界纪录450°旋转舞台 Answer: 十大中文金曲全球华人最受欢迎男歌手 Answer: 美国两度封[郭富城日] Answer: 香港十大杰出青年 Answer: 英国万像国际华语电影节最佳男主角 Answer: 两届台湾电影金马奖最佳男主角奖 Answer: 蛇 Answer: 171cm Answer: 中国香港 Answer: 64kg Answer: 港媒报道，郭富城与方媛公开交往3个月以来，常送女方价值数千元的首饰、巧克力等礼物，方媛曾抱怨城城不肯送她10万元的爱马仕包，又传一直租房的方媛想在上海买房，看中两千万的豪宅，郭富城却老找借口拒陪方媛看房，有意藉此疏远女友。郭富城女友欲购上海两户豪宅 Answer: 熊黛林与郭富城拍拖6年，近年恋情逐步浮面。刚收到钻石吊坠做情人节礼物的她，昨天(2月23日)提起男友时竟一反常态，严肃指自己不想再提郭富城，并强调大家只是朋友，她还祝福郭富城早日找到对象，令人怀疑两人已分手。 Answer: 据新浪娱乐报道，12月2日晚上8点，郭富城在香港出席某杂志活动时，首度公开回应了这段新恋情。被问到女友的过去时，他说:“每个人都有过去，我不会去计较过去怎么样”。至于未来是否有结婚打算，郭富城表示:“目前先了解，至于未来是怎样，说真的我不知道。” Answer: 这不是段子！郭富城和方媛终于大婚，婚礼现场，方爸爸非常激动，动情地对郭天王说:“我从小就听你的歌长大的，现在我把女儿交给你，希望你好好对待她。”方爸保养确实好，看起来不比女婿老啊甜蜜！方媛爸托付女儿给郭富城还说了这句话 Answer: 14日下午有港媒直击郭富城与方媛现身逛街，郭富城看到记者便笑说:“今天带老婆挑母亲节礼物”，方媛则紧紧揽住郭富城手臂当天方媛穿着T裇与长裙，腹部已微微隆起，孕味挡不住郭富城方媛婚后首同框手牵手恩爱购物 Answer: 1965-10-26 Answer: 爱你 Answer: 最好的声音 Answer: A型 Answer: 天蝎座\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [75,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [46,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m郭富城\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n","Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(input_query, graph)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#return tokenizer.decode(output_ids[0], skip_special_tokens=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(combined_input, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m126\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m response_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_text}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1441\u001b[0m, in \u001b[0;36mPeftModelForSeq2SeqLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1440\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1441\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1393\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1388\u001b[0m         )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1393\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:503\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    501\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    502\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 503\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1169\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;66;03m# output_attentions=True & head_mask can not be supported when using SDPA, fall back to\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;66;03m# the manual implementation that requires a 4D causal mask in all cases.\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(attention_mask, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:421\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture the controlflow `is_causal=attention_mask is None and q_len > 1`\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# used as an SDPA argument. We keep compatibility with these tracing tools by always using SDPA's `attn_mask` argument in case we are tracing.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).\u001b[39;00m\n\u001b[1;32m    415\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    416\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing()\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mis_compiling())\n\u001b[1;32m    419\u001b[0m )\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tracing:\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]}]}